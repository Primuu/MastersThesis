\chapter{Przegląd literatury}
Rozdział ten stanowi zestawienie współczesnych badań dotyczących analizy sentymentu i~emocji w kontekście przetwarzania języka naturalnego. Omówione zostaną zarówno porównania tradycyjnych podejść statystycznych, jak i nowoczesnych metod opartych na głębokim uczeniu.

\section{Modele statystyczne}
Wśród klasycznych metod analizy sentymentu, tj. metod stosowanych przed powszechnym wykorzystaniem sieci neuronowych, najczęściej wykorzystywanymi podejściami były Maszyna Wektorów Nośnych (SVM) oraz \textit{Naive Bayes}. \textit{Naive Bayes} cechuje się jednak niższą skutecznością, to z powodu podatności na problemy związane z niezależnością cech. Model ten zakłada bowiem warunkową niezależność między słowami, co w praktyce często nie jest prawdą, zwłaszcza w przypadku tekstów naturalnych o złożonej strukturze~\cite{OracleBayes}. 

Badania przeprowadzone w ostatnich latach potwierdzają, że \textit{Naive Bayes} generalnie radzi sobie gorzej w porównaniu do nowszych metod. Przykładowo, w pracy z 2021 roku~\cite{TextClassOnBigData}, autorzy porównali skuteczność SVM i \textit{Naive Bayes}, z uwzględnieniem różnych technik ekstrakcji cech, w~kontekście analizy komentarzy z blogów. W badaniu zastosowano zarówno tradycyjne metody reprezentacji tekstu, takie jak TF-IDF, jak i podejścia hybrydowe, które łączyły klasyczne modele z elementami głębokiego uczenia. Trening modeli i ich ewaluacja odbywały się~przy~użyciu standardowych miar klasyfikacyjnych, takich jak dokładność (ang. \textit{accuracy}). W porównaniu do powyższego badania niniejsza praca poszerza zakres modeli o architektury oparte na~głębokich sieciach neuronowych oraz modele transformatorowe. Ponadto, podejście zastosowane w~omawianym badaniu różni się od podejścia niniejszej pracy, gdzie skoncentrowano się~przede wszystkim na porównaniu wydajności algorytmów uczenia maszynowego bez~stosowania technik przetwarzania i ekstrakcji cech. Omawiane badanie stanowi jednak punkt odniesienia dla~niniejszego projektu, zwłaszcza w kontekście klasycznych metod klasyfikacji tekstu. Wyniki przeprowadzonych eksperymentów potwierdziły, że pomimo swojej prostoty i niskich wymagań obliczeniowych, algorytm \textit{Naive Bayes} cechuje się niższą skutecznością w~porównaniu do~Maszyny Wektorów Nośnych (SVM).

Podobne wnioski płyną z pracy z roku 2022~\cite{HateClassification}, w której autorzy porównali algorytmy SVM i \textit{Naive Bayes} pod kątem klasyfikacji mowy nienawiści w mediach społecznościowych. W~badaniu zastosowano standardowe techniki przygotowania danych, co jest zgodne z podejściem wykorzystanym w niniejszej pracy, a następnie przeprowadzono trening i ewaluację modeli przy użyciu standardowych miar skuteczności, które również zostaną użyte w niniejszym badaniu. W odróżnieniu od omawianej pracy, która koncentruje się na prostych klasyfikatorach oraz~specyficznym zadaniu detekcji mowy nienawiści, niniejsze badanie rozszerza zakres analizy o klasyfikację sentymentu oraz emocji, porównując jednocześnie także modele nowsze i bardziej zaawansowane. Wyniki omawianej pracy wskazały, że algorytm SVM osiągnął bardzo wysoką dokładność klasyfikacji, sięgającą około 99\%, podczas gdy algorytm \textit{Naive Bayes} uzyskał znacznie niższy wynik, wynoszący około 50\%.

Dlatego w niniejszej pracy skupiono się na modelu SVM, który mimo swojej prostoty nadal okazuje się konkurencyjny w niektórych zadaniach klasyfikacyjnych. Przykładem jest badanie~\cite{PLMsvsSVM}, w którym autorzy porównali skuteczność Maszyny Wektorów Nośnych z wcześniej wytrenowanymi modelami językowymi (ang. \textit{Pretrained Language Model}, PLM), takimi jak BERT, na czterech zbiorach danych. Wyniki wykazały, że nawet po dostrojeniu, PLM-y nie przewyższyły znacząco prostego klasyfikatora SVM. Autorzy sugerują, że w zadaniach klasyfikacji tekstu tradycyjne podejście oparte na SVM, wspierane staranną inżynierią cech, może być bardziej efektywne kosztowo i wydajnościowo niż stosowanie zaawansowanych modeli językowych. Podczas gdy opisane badanie kładzie nacisk na inżynierię cech oraz wykorzystanie gotowych modeli PLM, w niniejszej pracy zastosowano podejście oparte na samodzielnym trenowaniu modeli (za~wyjątkiem BERT-a, który jest wstępnie wytrenowany) bez ingerencji w~przetwarzanie tekstu czy dodatkową inżynierię cech, co pozwoli na analizę ich zachowania i~skuteczności w~kontekście różnych zadań NLP. Niemniej, gdy teksty zawierają niejasności, takie jak ironia, model SVM może mieć trudności w uchwyceniu pełnego kontekstu, co ogranicza jego skuteczność.

\section{Modele sekwencyjne}
Modele sekwencyjne, takie jak LSTM i GRU, wykazują wysoką skuteczność w analizie sentymentu i emocji, a to dzięki zdolności do modelowania długoterminowych zależności w danych tekstowych. W szczególności są one bardziej efektywne w przypadku dłuższych i bardziej złożonych tekstów. W badaniu~\cite{SAKapur} przeprowadzono porównanie trzech podejść do analizy sentymentu na danych pochodzących z różnych platform społecznościowych. Autorzy wykorzystali metody leksykalne oparte na słownikach (\textit{TextBlob}), klasyczny model probabilistyczny \textit{Naive Bayes} oraz model sieci neuronowej LSTM, zdolny do wychwytywania wzorców i długoterminowych zależności w tekście. Dane zostały poddane standardowym procesom przygotowania, obejmującym tokenizację i normalizację tekstu, a każdy model trenowano oddzielnie na zbiorach pochodzących z poszczególnych platform. Ewaluacja skuteczności odbywała się przy użyciu standardowych miar. Wyniki wykazały, że model LSTM systematycznie przewyższał zarówno podejścia leksykalne jak i probablistyczne. W porównaniu do omawianego badania niniejsza praca rozszerza zakres analizowanych modeli. Podobnie jak w opisywanym badaniu, opiera się na danych tekstowych z mediów społecznościowych, jednak różni się podejściem metodologicznym, koncentrując się na minimalnej ingerencji w preprocessing danych. Ponadto analiza obejmuje zarówno klasyfikację sentymentu, jak i emocji oraz dodatkowo rozszerza ocenę modeli o aspekt efektywności obliczeniowej i czasu treningu.

W publikacji~\cite{SCMohamed} porównano ponad 100 podejść opartych na głębokim uczeniu do klasyfikacji sentymentu na 21 publicznie dostępnych zbiorach danych z recenzjami klientów. Analiza ta wykazała, że modele sekwencyjne, takie jak LSTM i GRU, osiągają generalnie wyższą dokładność niż tradycyjne metody klasyfikacji, na przykład SVM. Autorzy wspomnianej pracy zauważyli ponadto, że modele trenowane na zbalansowanych zbiorach danych uzyskiwały wyższe wyniki niż te uczone na zbiorach niezbalansowanych, co stanowi istotną przesłankę do~stosowania technik równoważenia klas. Proces przetwarzania danych ograniczał się natomiast do~standardowych procedur, bez zastosowania zaawansowanej inżynierii cech, co jest zbieżne z~podejściem przyjętym w niniejszym badaniu. W odróżnieniu od pracy~\cite{SCMohamed}, niniejsze badanie nie tylko porównuje skuteczność wybranych modeli uczenia maszynowego przy minimalnej ingerencji w dane wejściowe, ale również analizuje wpływ podejścia wielozadaniowego na~jakość predykcji. Głównym celem jest stworzenie neutralnego, ujednoliconego środowiska eksperymentalnego, które umożliwia obiektywną ocenę skuteczności oraz efektywności wybranych modeli w zadaniach jedno- i wielozadaniowych.

\section{Modele transformatorowe}
Modele transformatorowe, takie jak BERT, stanowią obecnie jedno z najskuteczniejszych podejść w analizie sentymentu. Ich przewaga nad wcześniejszymi technikami, wynika przede wszystkim z zastosowania mechanizmu samouwagi (ang. \textit{self-attention}), który pozwala modelowi analizować kontekst danego słowa zarówno z lewej, jak i z prawej strony. W pracy autorów modelu BERT~\cite{BERT} przedstawiono wyniki eksperymentów, które wykazały, że model ten przewyższa wcześniejsze podejścia, zarówno tradycyjne, jak i oparte na sieciach neuronowych, w~szeregu standardowych zadań NLP, takich jak m.in. klasyfikacja tekstu czy analiza sentymentu. Na~tej~podstawie można wysunąć hipotezę, że w ramach przeprowadzonych w niniejszej pracy eksperymentów, model BERT osiągnie najlepsze wyniki spośród analizowanych architektur.

Również w nowszych badaniach dotyczących analizy emocji, modele transformatorowe potwierdzają swoją przewagę. Przykładem jest praca~\cite{EmotionTra}, w której przeprowadzono porównanie kilku modeli, w tym DistilBERT, ELECTRA, Twitter-RoBERTa oraz LSTM z osadzaniem GloVe, w zadaniu klasyfikacji emocji na zbiorze GoEmotions. Dane przetworzono, poprzez zmniejszenie liczby etykiet (z 6 do 4) oraz przez usunięcie m.in. znaczników HTML, adresów e-mail, znaków interpunkcyjnych, specjalnych oraz stopwordów. Wyniki eksperymentów wykazały, że~wariant modelu transformatorowego BERT osiągnął najwyższą dokładność, mimo ograniczonej liczby danych treningowych. Co istotne, autorzy zauważyli, że intensywne przetwarzanie tekstu może pogarszać wyniki modeli transformatorowych, które do skutecznego działania wymagają dostępu do pełnego kontekstu językowego. W niniejszej pracy skupiono się~na~minimalnej ingerencji w~dane wejściowe, tak aby zapewnić optymalne warunki porównania modeli bez dodatkowej inżynierii cech, co jest podejściem zbieżnym z obserwacjami autorów. Dodatkowo, w przeciwieństwie do badania~\cite{EmotionTra}, zastosowano zbalansowane zbiory danych oraz~rozszerzono zakres eksperymentów o analizę wpływu uczenia wielozadaniowego.

Skuteczność modelu BERT w zadaniu klasyfikacji sentymentu została również potwierdzona w badaniu~\cite{LSTMandBERT}, w którym autorzy porównali m.in. model LSTM oraz model BERT. Eksperymenty przeprowadzono na zbiorze danych z Twittera, klasyfikując wypowiedzi na pięć poziomów sentymentu: od skrajnie negatywnego do skrajnie pozytywnego. Modele oceniano przy użyciu standardowych miar skuteczności, takich jak dokładność, precyzja, czułość oraz~F1-score. W~badaniu wykorzystano klasyczne techniki przetwarzania tekstu, w tym usuwanie znaków specjalnych, tokenizację oraz eliminację stopwordów. Wyniki wykazały, że model BERT osiągnął najwyższe wskaźniki skuteczności, przewyższając zarówno klasyczny model oparty na~częstotliwości słów, jak i model LSTM. Choć LSTM radził sobie zauważalnie lepiej niż podejście częstotliwościowe, to nadal ustępował BERT-owi pod względem dokładności. Niniejsza praca rozszerza analizę o modele SVM oraz uwzględnia wpływ uczenia wielozadaniowego.

\newpage
\section{Podsumowanie}
Badania jednoznacznie potwierdzają wyższą skuteczność modeli nowszej generacji, zwłaszcza w zadaniach wymagających rozpoznawania kontekstu. Wśród nich BERT często wykazuje się najwyższą skutecznością, jednak kosztem większego zapotrzebowania na zasoby obliczeniowe i czas treningu.

Podczas analizy dostępnych badań zauważono jednak kilka luk badawczych. Po pierwsze, nie zidentyfikowano pracy, która w sposób systematyczny i kolektywny porównywałaby modele NLP od klasycznych metod, przez sieci rekurencyjne, aż po architektury transformatorowe~--~a~jednocześnie uwzględniała wpływ uczenia wielozadaniowego na wydajność modeli. 

Wiele omawianych badań zakładało uprzednią inżynierię cech, rozbudowany preprocessing danych lub optymalizację hiperparametrów. Choć takie zabiegi poprawiają dokładność, mogą jednocześnie utrudniać porównanie natywnej skuteczności algorytmów. W niniejszej pracy celowo ograniczono ingerencję w~dane wejściowe, aby stworzyć możliwie najbardziej neutralne środowisko testowe, pozwalające na~ocenę modeli w ich podstawowej formie.

Dodatkowo przeprowadzona zostanie analiza czasu trenowania poszczególnych modeli. Choć skuteczność predykcyjna jest zwykle głównym kryterium porównań, to właśnie koszt obliczeniowy decyduje często o praktycznej przydatności danego rozwiązania, zwłaszcza w systemach produkcyjnych o ograniczonych zasobach. Aspekt ten bywa pomijany lub traktowany marginalnie w wielu pracach.

\endinput