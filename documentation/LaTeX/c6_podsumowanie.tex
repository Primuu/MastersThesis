\chapter{Wnioski i podsumowanie}
Analizując wyniki uzyskane przez poszczególne modele, można dojść do wniosku, który rzutuje na całą dalszą analizę podsumowującą: analiza sentymentu okazała się zadaniem trudniejszym niż analiza emocji. Z obserwacji błędów modeli oraz charakterystyki statystycznej danych można stwierdzić, że trudność w analizie sentymentu wynika z podobieństwa klasy neutralnej do klas pozytywnej i negatywnej. Brak cech charakterystycznych dla tej klasy sprawia, że modele mają trudności w jej jednoznacznym odróżnieniu od reszty, co prowadzi do większej liczby błędów klasyfikacyjnych. Z kolei analiza emocji była łatwiejsza, ponieważ teksty w tym zadaniu były wyraźnie nacechowane, co dało się zauważyć w charakterystyce statystycznej tego zbioru. Łatwość w poprawnym przypisywaniu właściwej emocji, potwierdza analiza błędów modeli. Część klas była rozpoznawana przez modele niemal bezbłędnie, co świadczy o intensywnym nacechowaniu próbek w zbiorze. Dlatego też analiza sentymentu traktowana będzie jako bardziej wymagający benchmark. Na tej podstawie przedstawione będą dalsze wnioski.

\section{Najskuteczniejszy model w klasyfikacji sentymentu i emocji}
Po przeprowadzeniu eksperymentów można stwierdzić, że najlepsze rezultaty uzyskano dla modelu BERT. W klasyfikacji sentymentu, BERT przewyższał inne modele, osiągając najwyższe wyniki. Model ten, wymagający pod względem zasobów, wykazał się wyższą skutecznością o kilka punktów procentowych w porównaniu do pozostałych podejść. W przypadku analizy emocji, różnice pomiędzy modelami były mniej zauważalne, a BERT osiągnął wyniki niemal identyczne do LSTM i GRU. Sugeruje to, że w prostszych zadaniach BERT jest nadmiernym rozwiązaniem. W takim przypadku LSTM i GRU czy nawet SVM, które są szybsze i mniej zasobożerne, mogą okazać się bardziej efektywne.

\section{Wpływ uczenia wielozadaniowego}
W przypadku uczenia wielozadaniowego wyniki nie wykazały istotnej poprawy ani pogorszenia w porównaniu do modeli jednozadaniowych. Dla BERT-a, wyniki wersji wielozadaniowej były nieznacznie gorsze niż w wersji jednozadaniowej. Natomiast w przypadku LSTM i GRU, uczenie wielozadaniowe miało nieznaczny, korzystny wpływ na wyniki. Z tego punktu widzenia, warto rozważyć użycie dwóch oddzielnych modeli, co zapewnia prostotę, łatwiejszą interpretację wyników i wyższą efektywność.

\newpage
\section{Czas treningu i zasoby obliczeniowe}
W zakresie czasu treningu, BERT okazał się najwolniejszym modelem. Wysokie zapotrzebowanie na moc obliczeniową BERT-a jest istotnym czynnikiem, który należy wziąć pod uwagę przy jego wyborze. Z kolei LSTM i GRU wymagały znacznie mniej czasu. Są to modele o mniejszej liczbie parametrów, co sprawia, że są bardziej efektywne czasowo i wymagają mniejszych zasobów obliczeniowych, przy zachowaniu równie wysokiej skuteczności w prostych zadaniach. SVM charakteryzował się najszybszym czasem treningu i choć nie potrzebuje dużej mocy obliczeniowej, generalnie wypada gorzej niż bardziej złożone modele, szczególnie w zadaniach bardziej złożonych.

\section{Wyzwania i ograniczenia modeli NLP w analizie sentymentu}
Wyzwania związane z analizą sentymentu wynikają głównie z trudności w rozróżnieniu klasy neutralnej od klas pozytywnej i negatywnej. Analiza emocji okazała się zadaniem łatwiejszym, ponieważ teksty były prawdopodobnie silnie nacechowane emocjonalnie, co ułatwiało klasyfikację. Jednak wciąż niektóre modele miały trudności z klasyfikacją mniej wyraźnych emocji, co~wskazuje na pewne ograniczenia. Modele, które potrafią uchwycić bardziej złożone zależności semantyczne, wykazują lepszą skuteczność, nawet w zadaniach, które na pierwszy rzut oka wydają się bardziej jednoznaczne.

W kontekście analizy sentymentu dużą uwagę poświęca się również problemowi biasu (uprzedzeń) w danych, który może negatywnie wpływać na jakość wyników~\cite{Bias1}. Bias w danych objawia się jako systematyczne odchylenia lub nierównowagi, które mogą wynikać z różnorodnych źródeł, takich jak np. nieadekwatne reprezentowanie grup demograficznych, tendencyjne źródła danych czy stronnicze etykietowanie~\cite{Bias2}. Obecność biasu prowadzi do ograniczonej zdolności generalizacji modeli, co może skutkować preferowaniem lub dyskryminowaniem określonych grup oraz utrwalaniem stereotypów językowych. W związku z tym współczesne badania w~dziedzinie NLP podkreślają konieczność identyfikacji i minimalizacji biasu poprzez metody takie jak zrównoważony dobór danych, analiza wpływu cech demograficznych, czy zastosowanie metod regularyzacji i uczenia przeciwdziałającego uprzedzeniom~\cite{Bias3}.

\section{Podsumowanie}
Z przeprowadzonych analiz wynika, że BERT jest najskuteczniejszym modelem w zadaniach trudniejszych, w tym wypadku – analizie sentymentu. W analizie emocji, różnice między modelami były mniejsze, a LSTM i GRU osiągnęły wyniki niemal identyczne do BERT-a. Uczenie wielozadaniowe miało marginalny wpływ na wyniki. Jeśli chodzi o czas treningu, BERT wymaga znacznie większych zasobów obliczeniowych i/lub dłuższego czasu treningu, podczas gdy LSTM i GRU oferują dobry kompromis między dokładnością a szybkością trenowania. SVM, choć szybki i efektywny w zakresie zasobów, nie zapewnia tak wysokiej jakości wyników jak bardziej zaawansowane modele.

\endinput